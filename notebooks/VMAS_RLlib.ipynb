{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NsC_EwfCF5I"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cP9ijqwvIXGd",
    "outputId": "325a91db-8e61-49ab-e804-a649c16fb86d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "! git clone https://github.com/proroklab/VectorizedMultiAgentSimulator.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjnXLxaOMLuv",
    "outputId": "3521dbcf-8199-4f94-a199-867ddd3b358b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "%cd /content/VectorizedMultiAgentSimulator\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "!apt-get update\n",
    "!apt-get install -y x11-utils \n",
    "!apt-get install -y xvfb\n",
    "!apt-get install -y imagemagick\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wilTW60cNr4",
    "outputId": "05ca6735-9cee-4e9e-b8dd-be4738f57cca",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "!pip install pyvirtualdisplay\n",
    "import pyvirtualdisplay\n",
    "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAAA3DXGCLkF"
   },
   "source": [
    "## Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6Kknt4W8gym"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "has_gpu = torch.cuda.is_available()\n",
    "os.environ[\"RLLIB_NUM_GPUS\"] = \"1\" if has_gpu else \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DFsqhhL97JFh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   'nearest': pil_image.NEAREST,\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   'bilinear': pil_image.BILINEAR,\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   'bicubic': pil_image.BICUBIC,\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   if hasattr(pil_image, 'HAMMING'):\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   if hasattr(pil_image, 'BOX'):\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   if hasattr(pil_image, 'LANCZOS'):\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   _nlv = LooseVersion(_np_version)\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   other = LooseVersion(other)\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/pandas/compat/numpy/function.py:125: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   if LooseVersion(_np_version) >= LooseVersion(\"1.17.0\"):\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:568: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   (np.object, string),\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:569: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   (np.bool, bool),\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:100: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   np.object: SlowAppendObjectArrayToTensorProto,\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m /opt/anaconda3/envs/env/lib/python3.7/site-packages/tensorboard/util/tensor_util.py:101: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[2m\u001b[36m(pid=44668)\u001b[0m   np.bool: SlowAppendBoolArrayToTensorProto,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=44668)\u001b[0m 2023-01-10 09:23:33,206\tWARNING env.py:82 -- Env checking isn't implemented for VectorEnvs, RemoteBaseEnvs, ExternalMultiAgentEnv, ExternalEnvs or environments that are Ray actors.\n",
      "\u001b[2m\u001b[36m(PPO pid=44650)\u001b[0m 2023-01-10 09:23:33,291\tWARNING env.py:82 -- Env checking isn't implemented for VectorEnvs, RemoteBaseEnvs, ExternalMultiAgentEnv, ExternalEnvs or environments that are Ray actors.\n",
      "\u001b[2m\u001b[36m(PPO pid=44650)\u001b[0m 2023-01-10 09:23:33,310\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=44668)\u001b[0m 2023-01-10 09:23:33,458\tWARNING agent_collector.py:156 -- Provided tensor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=44668)\u001b[0m [ 1.2652065   0.83859646  0.6635986  -0.68469733 -0.13763176  0.5854714\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=44668)\u001b[0m  -0.97472847 -0.10603119]\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=44668)\u001b[0m  does not match space of view requirements actions.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=44668)\u001b[0m Provided tensor has shape (8,) and view requirement has shape shape None.Make sure dimensions match to resolve this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                        </th><th>custom_metrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname                    </th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                          </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                                    </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_balance_591fb_00000</td><td style=\"text-align: right;\">               14160000</td><td>{&#x27;num_env_steps_sampled&#x27;: 14160000, &#x27;num_env_steps_trained&#x27;: 14160000, &#x27;num_agent_steps_sampled&#x27;: 14160000, &#x27;num_agent_steps_trained&#x27;: 14160000}</td><td>{&#x27;rewards/0_mean&#x27;: 99.64384879943259, &#x27;rewards/0_min&#x27;: -6.2609405517578125, &#x27;rewards/0_max&#x27;: 141.73487854003906, &#x27;rewards/1_mean&#x27;: 99.64384879943259, &#x27;rewards/1_min&#x27;: -6.2609405517578125, &#x27;rewards/1_max&#x27;: 141.73487854003906, &#x27;rewards/2_mean&#x27;: 99.64384879943259, &#x27;rewards/2_min&#x27;: -6.2609405517578125, &#x27;rewards/2_max&#x27;: 141.73487854003906, &#x27;rewards/3_mean&#x27;: 99.64384879943259, &#x27;rewards/3_min&#x27;: -6.2609405517578125, &#x27;rewards/3_max&#x27;: 141.73487854003906, &#x27;agent 0/pos_rew_mean&#x27;: 99.64384879943259, &#x27;agent 0/pos_rew_min&#x27;: -6.2609405517578125, &#x27;agent 0/pos_rew_max&#x27;: 141.73487854003906, &#x27;agent 0/ground_rew_mean&#x27;: 0.0, &#x27;agent 0/ground_rew_min&#x27;: 0.0, &#x27;agent 0/ground_rew_max&#x27;: 0.0, &#x27;agent 1/pos_rew_mean&#x27;: 99.64384879943259, &#x27;agent 1/pos_rew_min&#x27;: -6.2609405517578125, &#x27;agent 1/pos_rew_max&#x27;: 141.73487854003906, &#x27;agent 1/ground_rew_mean&#x27;: 0.0, &#x27;agent 1/ground_rew_min&#x27;: 0.0, &#x27;agent 1/ground_rew_max&#x27;: 0.0, &#x27;agent 2/pos_rew_mean&#x27;: 99.64384879943259, &#x27;agent 2/pos_rew_min&#x27;: -6.2609405517578125, &#x27;agent 2/pos_rew_max&#x27;: 141.73487854003906, &#x27;agent 2/ground_rew_mean&#x27;: 0.0, &#x27;agent 2/ground_rew_min&#x27;: 0.0, &#x27;agent 2/ground_rew_max&#x27;: 0.0, &#x27;agent 3/pos_rew_mean&#x27;: 99.64384879943259, &#x27;agent 3/pos_rew_min&#x27;: -6.2609405517578125, &#x27;agent 3/pos_rew_max&#x27;: 141.73487854003906, &#x27;agent 3/ground_rew_mean&#x27;: 0.0, &#x27;agent 3/ground_rew_min&#x27;: 0.0, &#x27;agent 3/ground_rew_max&#x27;: 0.0}</td><td>2023-01-10_17-20-03</td><td>False </td><td style=\"text-align: right;\">           197.441</td><td>{}             </td><td style=\"text-align: right;\">             141.735</td><td style=\"text-align: right;\">              99.6438</td><td style=\"text-align: right;\">            -6.26094</td><td style=\"text-align: right;\">                 311</td><td style=\"text-align: right;\">           71095</td><td>92d3e75facb64bf3a6a5db4ec0551b6e</td><td>wosersysydeMacBook-Pro.local</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 20.392005970648356, &#x27;cur_kl_coeff&#x27;: 6.681911775230489e-54, &#x27;cur_lr&#x27;: 5e-06, &#x27;total_loss&#x27;: 2.9767663796033177, &#x27;policy_loss&#x27;: 0.0017569990937772672, &#x27;vf_loss&#x27;: 2.9750093873058048, &#x27;vf_explained_var&#x27;: 0.9874570196228368, &#x27;kl&#x27;: 0.0038214488556637402, &#x27;entropy&#x27;: 1.807006427007062, &#x27;entropy_coeff&#x27;: 0.0}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 4096.0, &#x27;num_grad_updates_lifetime&#x27;: 131880.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 279.5}}, &#x27;num_env_steps_sampled&#x27;: 14160000, &#x27;num_env_steps_trained&#x27;: 14160000, &#x27;num_agent_steps_sampled&#x27;: 14160000, &#x27;num_agent_steps_trained&#x27;: 14160000}</td><td style=\"text-align: right;\">                       236</td><td>127.0.0.1</td><td style=\"text-align: right;\">                 14160000</td><td style=\"text-align: right;\">                 14160000</td><td style=\"text-align: right;\">               14160000</td><td style=\"text-align: right;\">                            60000</td><td style=\"text-align: right;\">               14160000</td><td style=\"text-align: right;\">                            60000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                        60000</td><td>{&#x27;cpu_util_percent&#x27;: 24.53402777777778, &#x27;ram_util_percent&#x27;: 64.95416666666668}</td><td style=\"text-align: right;\">44650</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 44.55475229622829, &#x27;mean_inference_ms&#x27;: 3.412697662916898, &#x27;mean_action_processing_ms&#x27;: 19.299814500179682, &#x27;mean_env_wait_ms&#x27;: 29.72847054005817, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 141.73487854003906, &#x27;episode_reward_min&#x27;: -6.2609405517578125, &#x27;episode_reward_mean&#x27;: 99.64384879943259, &#x27;episode_len_mean&#x27;: 197.44051446945338, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 311, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {&#x27;rewards/0_mean&#x27;: 99.64384879943259, &#x27;rewards/0_min&#x27;: -6.2609405517578125, &#x27;rewards/0_max&#x27;: 141.73487854003906, &#x27;rewards/1_mean&#x27;: 99.64384879943259, &#x27;rewards/1_min&#x27;: -6.2609405517578125, &#x27;rewards/1_max&#x27;: 141.73487854003906, &#x27;rewards/2_mean&#x27;: 99.64384879943259, &#x27;rewards/2_min&#x27;: -6.2609405517578125, &#x27;rewards/2_max&#x27;: 141.73487854003906, &#x27;rewards/3_mean&#x27;: 99.64384879943259, &#x27;rewards/3_min&#x27;: -6.2609405517578125, &#x27;rewards/3_max&#x27;: 141.73487854003906, &#x27;agent 0/pos_rew_mean&#x27;: 99.64384879943259, &#x27;agent 0/pos_rew_min&#x27;: -6.2609405517578125, &#x27;agent 0/pos_rew_max&#x27;: 141.73487854003906, &#x27;agent 0/ground_rew_mean&#x27;: 0.0, &#x27;agent 0/ground_rew_min&#x27;: 0.0, &#x27;agent 0/ground_rew_max&#x27;: 0.0, &#x27;agent 1/pos_rew_mean&#x27;: 99.64384879943259, &#x27;agent 1/pos_rew_min&#x27;: -6.2609405517578125, &#x27;agent 1/pos_rew_max&#x27;: 141.73487854003906, &#x27;agent 1/ground_rew_mean&#x27;: 0.0, &#x27;agent 1/ground_rew_min&#x27;: 0.0, &#x27;agent 1/ground_rew_max&#x27;: 0.0, &#x27;agent 2/pos_rew_mean&#x27;: 99.64384879943259, &#x27;agent 2/pos_rew_min&#x27;: -6.2609405517578125, &#x27;agent 2/pos_rew_max&#x27;: 141.73487854003906, &#x27;agent 2/ground_rew_mean&#x27;: 0.0, &#x27;agent 2/ground_rew_min&#x27;: 0.0, &#x27;agent 2/ground_rew_max&#x27;: 0.0, &#x27;agent 3/pos_rew_mean&#x27;: 99.64384879943259, &#x27;agent 3/pos_rew_min&#x27;: -6.2609405517578125, &#x27;agent 3/pos_rew_max&#x27;: 141.73487854003906, &#x27;agent 3/ground_rew_mean&#x27;: 0.0, &#x27;agent 3/ground_rew_min&#x27;: 0.0, &#x27;agent 3/ground_rew_max&#x27;: 0.0}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [117.07628440856934, 93.00224018096924, 116.0483570098877, 113.12100219726562, 109.36699295043945, 75.40217590332031, 123.17409896850586, 108.72024536132812, 115.05589008331299, 109.92096710205078, 79.85285186767578, 118.79481506347656, 130.62065410614014, 64.2946548461914, 58.69377899169922, 14.982879638671875, 93.89892578125, 98.98825073242188, 112.01651763916016, 119.82271575927734, 128.41402053833008, 79.90019226074219, 117.13457489013672, 117.35860443115234, 100.3802843093872, 95.09027290344238, 126.27787017822266, 126.06783294677734, 125.4280891418457, 135.2369384765625, 116.9592514038086, 106.66745281219482, 114.20149230957031, 105.5972900390625, 92.87841415405273, 63.0732536315918, 111.09952163696289, 115.36222839355469, 97.53299522399902, 112.32647895812988, 113.09326648712158, 5.3201904296875, 93.76148986816406, 116.50341606140137, 117.34215354919434, 125.92927169799805, 80.92390632629395, 57.2237548828125, 69.23227119445801, 87.05670166015625, 109.56949615478516, 105.14801788330078, 127.53852462768555, 117.05529022216797, 126.34617233276367, 70.83329010009766, 105.60393524169922, 99.51790237426758, 117.95056533813477, 110.15217590332031, 108.36830234527588, 74.40993881225586, 106.08880996704102, 111.71199035644531, 129.34356689453125, 117.26565551757812, 115.62464904785156, 60.24730682373047, 113.12211418151855, 85.47795104980469, 104.64946365356445, 84.17298603057861, 87.41825103759766, 101.14694881439209, 83.84781646728516, 117.29898071289062, 114.02300262451172, 60.63333511352539, 56.87834167480469, 89.46420669555664, 82.97163200378418, 102.17825698852539, 87.85149765014648, 93.42079448699951, 115.1454963684082, 132.74742698669434, 109.44936752319336, 117.98036193847656, 119.08479690551758, 117.1807632446289, 115.49753189086914, 76.57540893554688, 108.33441162109375, 117.22947692871094, 132.00692558288574, 98.90068054199219, 118.39411926269531, 14.444847106933594, 108.29718017578125, 111.18363189697266, 116.71433639526367, 115.18730926513672, 101.27680206298828, 109.97918319702148, 57.97298812866211, 88.78361511230469, 108.71320343017578, 9.400802612304688, 91.9937686920166, 132.56836700439453, 120.79468536376953, 20.652801513671875, 141.26381492614746, 87.47630310058594, 120.73787689208984, 99.53800773620605, 117.64168548583984, 115.69616317749023, 121.49663543701172, 116.57160186767578, 82.01677703857422, 84.24993896484375, 98.28810214996338, 111.34930419921875, 63.37464904785156, 112.82472229003906, 87.77971649169922, 111.5920295715332, 82.38740539550781, 112.0631217956543, 102.03842163085938, 110.16379165649414, 120.22867584228516, 76.16581726074219, 85.29930877685547, 100.02140235900879, 122.97039699554443, 95.63889694213867, 97.79639625549316, 100.66753387451172, 113.52615356445312, 116.59344482421875, -6.2609405517578125, 118.02297973632812, 105.95014572143555, 118.93058776855469, 102.16992568969727, 42.452239990234375, 105.828857421875, 126.16203308105469, 104.24900817871094, 75.74565505981445, 138.75174713134766, 121.76358413696289, 113.9814224243164, 97.04019165039062, 56.02977752685547, 64.58610153198242, 1.580230712890625, 105.53238677978516, 81.27451705932617, 95.98115539550781, 24.524131774902344, 10.918853759765625, 131.31895446777344, 113.03656768798828, 111.95329666137695, 111.07004261016846, 117.0172233581543, 125.7429084777832, 87.4390058517456, 117.99787139892578, 101.94406795501709, 111.33692932128906, 114.73672866821289, 104.9920539855957, 55.10760498046875, 116.36240768432617, 99.28965759277344, 123.17544555664062, 118.1320686340332, 118.23887252807617, 122.23132038116455, 115.03525066375732, 106.04404735565186, 114.39415550231934, 126.40606307983398, 1.1255950927734375, 87.20348358154297, 112.58648300170898, 82.70046615600586, 118.55970001220703, 119.95545196533203, 96.17192459106445, 112.03681182861328, 103.47395324707031, 111.6278076171875, 107.08552360534668, 113.71221160888672, 96.38127899169922, 70.23542022705078, 116.43207550048828, 94.46032333374023, 66.73311614990234, 120.61705780029297, 66.55838012695312, 89.37339210510254, 119.23163223266602, 117.31189727783203, 114.76184463500977, 113.97962951660156, 118.67873001098633, 116.92880249023438, 120.33320617675781, 119.79291343688965, -5.6340789794921875, 127.44141006469727, 92.38697814941406, 108.32819366455078, 73.40590286254883, 107.57826232910156, 103.09602355957031, 112.38995361328125, 64.8662338256836, 106.19150733947754, 117.78337478637695, 97.08245468139648, 124.4818115234375, 86.75025177001953, 125.18252182006836, 120.95628356933594, 128.63893699645996, 101.31093978881836, 109.28397369384766, 123.55352783203125, 102.82972717285156, 117.75715637207031, 106.3121109008789, 96.04522705078125, 116.45892333984375, 113.59090900421143, -4.5597686767578125, 110.57996368408203, 114.68016052246094, 89.32744598388672, 88.42433547973633, 137.8973159790039, 59.52796936035156, 41.957275390625, 113.18428421020508, 63.25364685058594, 102.19526863098145, 85.27239227294922, 117.37494659423828, 91.28302764892578, 113.89111328125, 107.20068550109863, 119.61580657958984, 107.76805877685547, 118.10227584838867, 54.0421142578125, 20.241790771484375, 78.71988105773926, 105.80561351776123, 99.95496559143066, 122.45042037963867, 29.008209228515625, 1.2701416015625, 118.01552963256836, 126.80803298950195, 115.02727317810059, 114.57110214233398, 115.73232078552246, 102.80484771728516, 129.0581932067871, 101.76990509033203, 141.73487854003906, 118.62461853027344, 60.67420959472656, 116.21189880371094, 75.29787826538086, 107.99716091156006, 56.375587463378906, 133.87681198120117, 102.17572402954102, 129.68142318725586, 119.16714096069336, 118.52069473266602, 119.1226577758789, 17.066757202148438, 116.18502044677734, 117.27503967285156, 122.46009826660156, 123.42143249511719, 7.4161224365234375, 117.71757507324219, 93.61946105957031, 105.1984748840332, 93.37629890441895, 65.90878677368164, 112.88870239257812, 113.14134979248047, 115.05036544799805, 112.28030300140381, 115.25590133666992, 117.42527770996094, 95.26692962646484, 116.20146560668945, 135.28208923339844, 107.35464477539062, 85.88555145263672], &#x27;episode_lengths&#x27;: [200, 160, 200, 200, 200, 200, 200, 200, 196, 200, 200, 200, 199, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 170, 200, 200, 192, 200, 200, 200, 189, 200, 200, 200, 200, 200, 200, 200, 200, 176, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 188, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 140, 200, 177, 200, 200, 200, 200, 200, 200, 200, 200, 155, 166, 200, 188, 200, 200, 200, 200, 200, 200, 185, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 170, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 150, 200, 175, 200, 200, 200, 200, 200, 200, 200, 200, 200, 181, 167, 166, 159, 200, 200, 200, 200, 143, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 151, 200, 200, 200, 200, 196, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 181, 200, 165, 200, 200, 188, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 176, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 170, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 185, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 44.55475229622829, &#x27;mean_inference_ms&#x27;: 3.412697662916898, &#x27;mean_action_processing_ms&#x27;: 19.299814500179682, &#x27;mean_env_wait_ms&#x27;: 29.72847054005817, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             28554.7</td><td style=\"text-align: right;\">           101.724</td><td style=\"text-align: right;\">       28554.7</td><td>{&#x27;training_iteration_time_ms&#x27;: 99196.919, &#x27;load_time_ms&#x27;: 27.45, &#x27;load_throughput&#x27;: 2185772.317, &#x27;learn_time_ms&#x27;: 49205.141, &#x27;learn_throughput&#x27;: 1219.385, &#x27;synch_weights_time_ms&#x27;: 2.088}</td><td style=\"text-align: right;\"> 1673342403</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">         14160000</td><td style=\"text-align: right;\">                 236</td><td>591fb_00000</td><td style=\"text-align: right;\">       9.7637</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 17:20:26,549\tWARNING tune.py:691 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-01-10 17:20:28,786\tERROR tune.py:758 -- Trials did not complete: [PPO_balance_591fb_00000]\n",
      "2023-01-10 17:20:28,787\tINFO tune.py:763 -- Total run time: 28636.93 seconds (28636.69 seconds for the tuning loop).\n",
      "2023-01-10 17:20:28,788\tWARNING tune.py:769 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "#  Copyright (c) 2022.\n",
    "#  ProrokLab (https://www.proroklab.org/)\n",
    "#  All rights reserved.\n",
    "\n",
    "import os\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib import BaseEnv, Policy, RolloutWorker\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.evaluation import Episode, MultiAgentEpisode\n",
    "from ray.rllib.utils.typing import PolicyID\n",
    "from ray.tune import register_env\n",
    "\n",
    "import wandb\n",
    "from vmas import make_env, Wrapper\n",
    "\n",
    "scenario_name = \"balance\"\n",
    "\n",
    "# Scenario specific variables.\n",
    "# When modifying this also modify env_config and env_creator\n",
    "n_agents = 4\n",
    "\n",
    "# Common variables\n",
    "continuous_actions = True\n",
    "max_steps = 200\n",
    "num_vectorized_envs = 96\n",
    "num_workers = 1\n",
    "vmas_device = \"cpu\"  # or cuda\n",
    "\n",
    "\n",
    "def env_creator(config: Dict):\n",
    "    env = make_env(\n",
    "        scenario_name=config[\"scenario_name\"],\n",
    "        num_envs=config[\"num_envs\"],\n",
    "        device=config[\"device\"],\n",
    "        continuous_actions=config[\"continuous_actions\"],\n",
    "        wrapper=Wrapper.RLLIB,\n",
    "        max_steps=config[\"max_steps\"],\n",
    "        # Scenario specific variables\n",
    "        n_agents=config[\"n_agents\"],\n",
    "    )\n",
    "    return env\n",
    "\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init()\n",
    "    print(\"Ray init!\")\n",
    "register_env(scenario_name, lambda config: env_creator(config))\n",
    "\n",
    "\n",
    "class EvaluationCallbacks(DefaultCallbacks):\n",
    "    def on_episode_step(\n",
    "        self,\n",
    "        *,\n",
    "        worker: RolloutWorker,\n",
    "        base_env: BaseEnv,\n",
    "        episode: MultiAgentEpisode,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        info = episode.last_info_for()\n",
    "        for a_key in info.keys():\n",
    "            for b_key in info[a_key]:\n",
    "                try:\n",
    "                    episode.user_data[f\"{a_key}/{b_key}\"].append(info[a_key][b_key])\n",
    "                except KeyError:\n",
    "                    episode.user_data[f\"{a_key}/{b_key}\"] = [info[a_key][b_key]]\n",
    "\n",
    "    def on_episode_end(\n",
    "        self,\n",
    "        *,\n",
    "        worker: RolloutWorker,\n",
    "        base_env: BaseEnv,\n",
    "        policies: Dict[str, Policy],\n",
    "        episode: MultiAgentEpisode,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        info = episode.last_info_for()\n",
    "        for a_key in info.keys():\n",
    "            for b_key in info[a_key]:\n",
    "                metric = np.array(episode.user_data[f\"{a_key}/{b_key}\"])\n",
    "                episode.custom_metrics[f\"{a_key}/{b_key}\"] = np.sum(metric).item()\n",
    "\n",
    "\n",
    "class RenderingCallbacks(DefaultCallbacks):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.frames = []\n",
    "\n",
    "    def on_episode_step(\n",
    "        self,\n",
    "        *,\n",
    "        worker: RolloutWorker,\n",
    "        base_env: BaseEnv,\n",
    "        policies: Optional[Dict[PolicyID, Policy]] = None,\n",
    "        episode: Episode,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        self.frames.append(base_env.vector_env.try_render_at(mode=\"rgb_array\"))\n",
    "\n",
    "    def on_episode_end(\n",
    "        self,\n",
    "        *,\n",
    "        worker: RolloutWorker,\n",
    "        base_env: BaseEnv,\n",
    "        policies: Dict[PolicyID, Policy],\n",
    "        episode: Episode,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        vid = np.transpose(self.frames, (0, 3, 1, 2))\n",
    "        episode.media[\"rendering\"] = wandb.Video(vid, fps=1 / base_env.vector_env.env.world.dt, format=\"mp4\")\n",
    "        self.frames = []\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    RLLIB_NUM_GPUS = int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\"))\n",
    "    num_gpus = 0.001 if RLLIB_NUM_GPUS > 0 else 0  # Driver GPU\n",
    "    num_gpus_per_worker = (\n",
    "        (RLLIB_NUM_GPUS - num_gpus) / (num_workers + 1) if vmas_device == \"cuda\" else 0\n",
    "    )\n",
    "\n",
    "    tune.run(\n",
    "        PPOTrainer,\n",
    "        stop={\"training_iteration\": 400},\n",
    "        checkpoint_freq=1,\n",
    "        keep_checkpoints_num=2,\n",
    "        checkpoint_at_end=True,\n",
    "        checkpoint_score_attr=\"episode_reward_mean\",\n",
    "        # callbacks=[\n",
    "        #     WandbLoggerCallback(\n",
    "        #        project=f\"{scenario_name}\",\n",
    "        #        api_key=\"\",\n",
    "        #    )\n",
    "        # ],\n",
    "        config={\n",
    "            \"seed\": 0,\n",
    "            \"framework\": \"torch\",\n",
    "            \"env\": scenario_name,\n",
    "            \"kl_coeff\": 0.01,\n",
    "            \"kl_target\": 0.01,\n",
    "            \"lambda\": 0.9,\n",
    "            \"clip_param\": 0.2,\n",
    "            \"vf_loss_coeff\": 1,\n",
    "            \"vf_clip_param\": float(\"inf\"),\n",
    "            \"entropy_coeff\": 0,\n",
    "            \"train_batch_size\": 60000,\n",
    "            \"rollout_fragment_length\": 125,\n",
    "            \"sgd_minibatch_size\": 4096,\n",
    "            \"num_sgd_iter\": 40,\n",
    "            \"num_gpus\": num_gpus,\n",
    "            \"num_workers\": num_workers,\n",
    "            \"num_gpus_per_worker\": num_gpus_per_worker,\n",
    "            \"num_envs_per_worker\": num_vectorized_envs,\n",
    "            \"lr\": 5e-6,\n",
    "            \"gamma\": 0.99,\n",
    "            \"use_gae\": True,\n",
    "            \"use_critic\": True,\n",
    "            \"batch_mode\": \"truncate_episodes\",\n",
    "            \"env_config\": {\n",
    "                \"device\": vmas_device,\n",
    "                \"num_envs\": num_vectorized_envs,\n",
    "                \"scenario_name\": scenario_name,\n",
    "                \"continuous_actions\": continuous_actions,\n",
    "                \"max_steps\": max_steps,\n",
    "                # Scenario specific variables\n",
    "                \"n_agents\": n_agents,\n",
    "            },\n",
    "            \"evaluation_interval\": 5,\n",
    "            \"evaluation_duration\": 1,\n",
    "            \"evaluation_num_workers\": 0,\n",
    "            \"evaluation_parallel_to_training\": False,\n",
    "            \"evaluation_config\": {\n",
    "                \"num_envs_per_worker\": 1,\n",
    "                \"env_config\": {\n",
    "                    \"num_envs\": 1,\n",
    "                },\n",
    "                # \"callbacks\": MultiCallbacks([RenderingCallbacks, EvaluationCallbacks]),\n",
    "            },\n",
    "            \"callbacks\": EvaluationCallbacks,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0NsC_EwfCF5I"
   ],
   "name": "VMAS: RLlib.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7.0 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b793f5bcb65162c203a8f7ab5f10da95fa3f746ebbc21691ed336cc34611f1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
